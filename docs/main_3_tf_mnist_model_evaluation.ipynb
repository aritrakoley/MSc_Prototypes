{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 0. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ImageUtilities import *\n",
    "from MNISTUtilities import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1. Read MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Digit Data============\n",
      "Reading: test-images-idx3-ubyte.gz  ...\n",
      "2051 10000 28 28\n",
      "(10000, 28, 28)\n",
      "Reading: test-labels-idx1-ubyte.gz  ...\n",
      "2049 10000 0 0\n",
      "(10000,)\n",
      "Reading: train-images-idx3-ubyte.gz  ...\n",
      "2051 60000 28 28\n",
      "(60000, 28, 28)\n",
      "Reading: train-labels-idx1-ubyte.gz  ...\n",
      "2049 60000 0 0\n",
      "(60000,)\n",
      "(60000, 784)\n",
      "Train Set:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAADFCAYAAAAWu4vIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD0NJREFUeJzt3X2wlmWdB/DfFQiHILR8odaNjIFADWVk0qajmUJ/aOviuNtGjqE5NBtWM7ruDE1SUzO6pWNjKDibM07UrKMzO7CtLxOyviyYrmIhFurosI5WNIqGeQw0Ee79A5oar+uwz+G5zvOcl89nxoH5cl/3/fNwg19vrucmNU0TAAA1vaPbAwAAI4+CAQBUp2AAANUpGABAdQoGAFCdggEAVKdgDBEppd6U0rqU0vaUUl9KaVNK6eJuzwUHK6W0NqXUpJSu7PYs0IqU0l+nlG5IKf1PSmnX/vv3mG7PNVwpGENASumEiLgnIg6JiC9ExN9FxKMRcXNKaUk3Z4ODkVL6bESc2O05YICmR8Q/RMQrEfFAl2cZ9hSMoWFhRIyJiHOapvnPpmn+q2maf4yIRyJiUXdHg4FJKR0WEddFxD91exYYoA1N00xpmubsiPj3bg8z3CkYQ8O4iNgdEa+/Lf99+Dli+LkmIp5omubWbg8CA9E0zd5uzzCS+I/X0LBq/7fXp5T+KqV0WErpCxExL/b9nyAMCymlU2PfU7dLuj0L0F1juz0AEU3TbEkpfSIi/iP+/Bvz7oj4YtM0t3VtMBiAlNIhEfH9iLi2aZqnuz0P0F0KxhCQUpoREasj4omI+GLs+6OSBRHxrymlN5qmuaWb80GLlkbEhIi4qtuDAN2nYAwN/xL7nlj8TdM0u/dn96aUDo+I5SmlW/3ZIENZSmlqRFwREYsjYnxKafxf/PD4/Rs/X2uaZk9XBgQ6zh6MoWF2RDz+F+XiTzZGxOERcVTnR4IBmRYRPRHxb7HvI35/+ici4p/3f392d0YDusETjKHhhYiYk1Ia1zTNm3+RnxIRb0TEju6MBS3bHBFnFPL7Y1/puDkitnZ0IqCrFIyhYUXs+8z1HSmlG2PfHoy/jYjPRsR1bysdMOQ0TfP7iPjvt+cppYiI55umyX4MhqKU0t/v/+7c/d+elVJ6KSJeappmfZfGGpZS0zTdnoGISCmdFfs2yR0f+x41/29E3BQR3/fn1gxXKaUmIq5qmmZZt2eBVuy/Z0vWN03ziU7OMtwpGABAdTZ5AgDVKRgAQHUKBgBQnYIBAFSnYAAA1XX0PRgH+PgPDFjTNKnT13QPU5N7mOHuQPewJxgAQHUKBgBQnYIBAFSnYAAA1SkYAEB1CgYAUJ2CAQBUp2AAANUpGABAdQoGAFCdggEAVKdgAADVKRgAQHUKBgBQnYIBAFSnYAAA1SkYAEB1CgYAUJ2CAQBUp2AAANWN7fYAAFDbtddem2Xnnntu8dj58+dn2XPPPVd7pFHHEwwAoDoFAwCoTsEAAKpTMACA6lLTNJ27WEqdu9gg+NCHPpRlxx9/fJatXr06y1JKxXMuWrQoy377298exHQDt2HDhmK+e/fujly/XU3TlL+og2i438MjTWkjX0TE5ZdfnmXLly/PsksvvbT6TAPhHh48kydPzrL169cXj500aVKWzZgxo/pMI9GB7mFPMACA6hQMAKA6BQMAqE7BAACqUzAAgOq8Krxg1qxZxfwHP/hBlp188slZVvpkTn+f1lm1atXAhqto6dKlxby/nfnQTaeffnqWXXzxxcVj9+7dm2XHHXdc9ZkYuvr6+rKsv0+RfPnLXx7scUYlTzAAgOoUDACgOgUDAKhOwQAAqhtVmzwPOeSQLCu9InbNmjXF9TNnzqw+U6vefPPNYl7azNbT09PSOb/xjW+0fK3rr7++pXMyNJTu64iI+fPnZ9nGjRuzrFOvqx+Ib33rW1l26KGHFo/ds2dPlm3btq36TAwv9913XzEvbfL82Mc+lmUPPfRQ9ZlGMk8wAIDqFAwAoDoFAwCoTsEAAKobVZs8S5sav/a1r7V1ztKGyHXr1rV1zpLvfe97xfyZZ57JsrvuuivLZs+enWUTJ04snvP973//AKdjqFmxYkUx/9znPpdla9euzbJPfepT1WcaiDPOOCPLSpvu+vOjH/0oyxYvXtzWTIwuH/nIR7LMJs+B8QQDAKhOwQAAqlMwAIDqFAwAoDoFAwCoblR9imQwvPbaa1m2YMGCLkzyZ4sWLcqyVatWZdmJJ57YgWkYbGPH5r+Mp02b1vL60qeG3vWud2VZ6V6vofQK/h//+MdZNmbMmJbPWVoPAzF9+vRujzDseYIBAFSnYAAA1SkYAEB1CgYAUN2I3OR5yimnFPPBeFVwX19fW+vf/e53Z9k73pH3vj/84Q/F9X/84x+z7Be/+EWWbd26Ncv62+TZ09OTZePGjcuy0mvS6bxjjjkmy3p7e1te/+CDD2bZYG3oLFmyZEmWTZo0qaW1GzduLOb33HNPWzPBWWed1e0Rhj1PMACA6hQMAKA6BQMAqE7BAACqG5GbPPvbIHbUUUe1dd7Nmzdn2XnnndfS2rlz5xbz22+/Pcve+973ZtnKlSuL6x944IGWrn/00Ue3dFxExCWXXJJlpc2spa9HRMRTTz2VZVu2bGn5+gzMT37yk5aPLW0WXr58eVvXnzx5cpaVNipfccUVxfVf+cpXDvraH/7wh4t56R4s+fnPf17MP//5z2dZJze+wkjgCQYAUJ2CAQBUp2AAANUpGABAdSNyk+dg2bVrV5Z99atfbWntqaeeWsxLGzpLvvSlLw0or63Vf8+IiKuuuirLbPKsY+HChVn2gQ98oOX1a9asybLSX/d++umnZ9m8efOK5yxt0ixt/BwM73znO4v51KlTW1rf33FTpkzJstNOO631wQBPMACA+hQMAKA6BQMAqE7BAACqUzAAgOpS0zSdu1hKHblYb29vMb/zzjuzrFO73Yeibdu2FfO9e/dm2eGHH55l/e3g37FjR5adc845Wfbwww//fyMeUNM0qa0THIRO3cOzZs0q5o8++miW9ffzUPLyyy9nWU9PT5b197r9bnr88cez7IQTTigem1Jrt8Ybb7xRzJctW5Zl1113XUvnHIiRfA8PRf29Wn7Dhg1ZNnHixCw7++yzi+vvvffe9gYbxg50D3uCAQBUp2AAANUpGABAdQoGAFDdiHxV+IMPPljMFy9enGUrV67MsiOPPLL6TJ309NNPZ1lpQ2XpFc8RETt37syyyy67LMuuvvrq4vr3vOc9WTZhwoTisZSNHz++mA9kQ2fJEUcc0dJxe/bsybLHHnuseOzq1auz7Nvf/nbLM5U2WpbWX3PNNS1lERHjxo3LstIG2dLsERF9fX3FnOGtv7+y4Pnnn8+yOXPmZFm7v/5GG08wAIDqFAwAoDoFAwCoTsEAAKobkZs8+1Pa0LVr164smzdvXnF9aaNjycaNG7PsxhtvLB5b2ig5ZcqULLvpppuK6x966KEse+aZZ7LskUceKa5vVekthldeeWXx2DFjxrR1LQbPLbfckmVbt27Nsttvvz3LNm/eXDznN7/5zbZmevbZZ7Osv3vr7S699NK2rg0R5Tfclt5ozMB4ggEAVKdgAADVKRgAQHUKBgBQnYIBAFQ3qj5FUnL33Xdn2dSpU4vHbt++Pcs+/elPZ9mTTz6ZZTt27Ciec926dVk2dmz+0/LKK68U15c+BcPwt23btmJe+tTEq6++mmW33nprcf1bb72VZU3TtDTTxIkTi/kFF1zQ0vr+XHTRRW2th3aVPo135plndmGSkcUTDACgOgUDAKhOwQAAqlMwAIDqRv0mz56enixbunRp8djzzz8/y37605+2df0XX3yxrfWMTKVXF0dE3HDDDR2e5M8WLlxYzD/4wQ+2tP6uu+4q5o899thBzwQ1/OY3v2npuCVLlhTzO+64o+Y4I4YnGABAdQoGAFCdggEAVKdgAADVpVbf4lflYil17mIt+s53vpNlxx57bPHYBQsWDPY4w8rOnTuLeWnj7Pz587Ps/vvvb+v6TdOktk5wEIbiPTwYJkyYkGU/+9nPisfOmjWrpXP29vYW84cffrj1wUYY9/DQtWfPnix74YUXisd+9KMfzbJf//rX1Wcaig50D3uCAQBUp2AAANUpGABAdQoGAFDdqHqT57Jly7Lssssuy7K1a9d2YpwR67vf/W6WtfvGUzpr5syZWdbqZs6IiJdeeinLxo8f39ZM0G1Tpkwp5oceemiWjZZNngfiCQYAUJ2CAQBUp2AAANUpGABAdQoGAFDdqPoUSWkX+9ix+Zdg2rRpxfUnnXRSlm3atKn9wYaYuXPnZtnHP/7xLNu+fXtx/X333Zdlu3fvbn8wBsW4ceOy7LbbbmvrnEceeWSWXXDBBcVj169f39a1oF0nn3xyS8c999xzxbz0qSk8wQAABoGCAQBUp2AAANUpGABAdaNqk2erjjvuuGL+wx/+MMt++ctfZtn5559ffabB0N9m1lWrVmVZ6Wty5plnFtfbtDe8zJs3L8tmzJjR1jmffPLJLFu9enVb54TBsnPnzpaOe/bZZ4v5iy++WHOcEcMTDACgOgUDAKhOwQAAqlMwAIDqbPIcgNJGx2OPPTbLFixYUP3aV199dTF/6qmnsqy0SbPk9ddfb/mcpQ2dGzZsaOk61DNz5sws6+npybK33nqruH7SpElZtmzZsrZmKl2rt7c3y/r6+tq6DgyWJ554oqXjjjjiiGI+efLkLHO/e4IBAAwCBQMAqE7BAACqUzAAgOoUDACgutQ0TecullLnLlbwyU9+MstOO+20LJs+fXpx/Wc+85nqM3VK6TXN/b3Se+XKlYM9ThVN06ROX7Pb93C7jj766Cz71a9+1dLa/nbFf/3rX8+yFStWDGywUco9PHTdfPPNWXbhhRcWj50zZ06WbdmypfpMQ9GB7mFPMACA6hQMAKA6BQMAqE7BAACqG1WbPFvV3+tgZ8+enWWlV8SuWbOm+kz9KW08/d3vfpdlpVfhbt++fVBm6hQb5AbusMMOy7JNmzZl2fve974sO/fcc4vnvPvuu9sfbJRyDzPc2eQJAHSUggEAVKdgAADVKRgAQHU2eTJs2SDHcOceZrizyRMA6CgFAwCoTsEAAKpTMACA6hQMAKA6BQMAqE7BAACqUzAAgOoUDACgOgUDAKhOwQAAqlMwAIDqFAwAoDoFAwCoTsEAAKpLTdN0ewYAYITxBAMAqE7BAACqUzAAgOoUDACgOgUDAKhOwQAAqlMwAIDqFAwAoDoFAwCoTsEAAKpTMACA6hQMAKA6BQMAqE7BAACqUzAAgOoUDACgOgUDAKhOwQAAqlMwAIDqFAwAoDoFAwCoTsEAAKpTMACA6v4PQ0le54Q1ZD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "10\n",
      "==============Digit Data============\n",
      "Reading: emnist-letters-mapping.txt  ...\n",
      "Reading: emnist-letters-test-images-idx3-ubyte.gz  ...\n",
      "2051 20800 28 28\n",
      "(20800, 28, 28)\n",
      "Reading: emnist-letters-test-labels-idx1-ubyte.gz  ...\n",
      "2049 20800 0 0\n",
      "(20800,)\n",
      "Reading: emnist-letters-train-images-idx3-ubyte.gz  ...\n",
      "2051 124800 28 28\n",
      "(124800, 28, 28)\n",
      "Reading: emnist-letters-train-labels-idx1-ubyte.gz  ...\n",
      "2049 124800 0 0\n",
      "(124800,)\n",
      "(124800, 784)\n",
      "Train Set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#Read 09\n",
    "print(\"==============Digit Data============\")\n",
    "d_class_labels = \"0123456789\"\n",
    "d_classes = len(d_class_labels)\n",
    "d_X_train, d_X_test, d_y_train, d_y_test = read_and_transform_MNIST_data(dir_path='../../../data/mnist_digit/', category='digit-data', transpose=False)\n",
    "sanity_check(d_X_train, d_X_test, d_y_train, d_y_test, d_class_labels)\n",
    "print(np.unique(d_y_train))\n",
    "print(len(d_class_labels))\n",
    "\n",
    "#Read az\n",
    "print(\"==============Digit Data============\")\n",
    "a_class_labels = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "a_classes = len(a_class_labels)\n",
    "a_X_train, a_X_test, a_y_train, a_y_test = read_and_transform_MNIST_data(dir_path='../../../data/mnist_az/gzip/', category='letter-data')\n",
    "a_y_train, a_y_test = (a_y_train - 1), (a_y_test - 1)\n",
    "sanity_check(a_X_train, a_X_test, a_y_train, a_y_test, a_class_labels)\n",
    "print(np.unique(a_y_train))\n",
    "print(len(a_class_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================Current Config: [50]\n",
      "====================Digits====================:\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\tf_cpu_env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3468 - acc: 0.9028\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1734 - acc: 0.9495\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1272 - acc: 0.9639\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1015 - acc: 0.9701\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0843 - acc: 0.9750\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0727 - acc: 0.9776\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0628 - acc: 0.9804\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0551 - acc: 0.9831\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0495 - acc: 0.9849\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0439 - acc: 0.9861\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.0927 - acc: 0.9743\n",
      "================================================Config: [50] => [loss: 0.092656200393755, acc: 0.9743000268936157]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 40,576\n",
      "Trainable params: 40,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 12s 94us/sample - loss: 0.9389 - acc: 0.7299\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 12s 96us/sample - loss: 0.6036 - acc: 0.8199\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 12s 93us/sample - loss: 0.5156 - acc: 0.8443\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 11s 91us/sample - loss: 0.4693 - acc: 0.8553\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 11s 92us/sample - loss: 0.4403 - acc: 0.8654\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 12s 97us/sample - loss: 0.4200 - acc: 0.8688\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 11s 90us/sample - loss: 0.4045 - acc: 0.8740\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 12s 94us/sample - loss: 0.3946 - acc: 0.8760\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 11s 91us/sample - loss: 0.3844 - acc: 0.8786\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 12s 93us/sample - loss: 0.3772 - acc: 0.8813\n",
      "20800/20800 [==============================] - 1s 49us/sample - loss: 0.4386 - acc: 0.8691\n",
      "================================================Config: [50] => [loss: 0.43863666674408774, acc: 0.8691346049308777]\n",
      "================================================Current Config: [100]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.2733 - acc: 0.9218\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1243 - acc: 0.9637\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0876 - acc: 0.9736\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0661 - acc: 0.9801\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0520 - acc: 0.9842\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0415 - acc: 0.9872\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0337 - acc: 0.9898\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0271 - acc: 0.9916\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0235 - acc: 0.9927\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0206 - acc: 0.9935\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.0883 - acc: 0.9748\n",
      "================================================Config: [100] => [loss: 0.08831386974003981, acc: 0.9747999906539917]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 26)                2626      \n",
      "=================================================================\n",
      "Total params: 81,126\n",
      "Trainable params: 81,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 14s 113us/sample - loss: 0.7940 - acc: 0.7680\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 14s 111us/sample - loss: 0.4646 - acc: 0.8584\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 14s 115us/sample - loss: 0.3902 - acc: 0.8784\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 14s 111us/sample - loss: 0.3516 - acc: 0.8886\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 14s 114us/sample - loss: 0.3279 - acc: 0.8953\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 14s 111us/sample - loss: 0.3098 - acc: 0.9003\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 14s 110us/sample - loss: 0.2957 - acc: 0.9043\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 14s 114us/sample - loss: 0.2852 - acc: 0.9073\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 14s 111us/sample - loss: 0.2754 - acc: 0.9098\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 14s 114us/sample - loss: 0.2668 - acc: 0.9133\n",
      "20800/20800 [==============================] - 1s 58us/sample - loss: 0.3743 - acc: 0.8890\n",
      "================================================Config: [100] => [loss: 0.37426547038243513, acc: 0.8890384435653687]\n",
      "================================================Current Config: [200]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 160us/sample - loss: 0.2357 - acc: 0.9316 - loss: 0.\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.0996 - acc: 0.9698\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.0672 - acc: 0.9797\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0487 - acc: 0.9845\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0368 - acc: 0.9879\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: 0.0276 - acc: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0225 - acc: 0.9927 - loss: \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0161 - acc: 0.9953\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.0159 - acc: 0.9949\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0122 - acc: 0.9959\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.0787 - acc: 0.9798\n",
      "================================================Config: [200] => [loss: 0.0786661292306977, acc: 0.9797999858856201]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 26)                5226      \n",
      "=================================================================\n",
      "Total params: 162,226\n",
      "Trainable params: 162,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 21s 169us/sample - loss: 0.6799 - acc: 0.7977\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 20s 164us/sample - loss: 0.3778 - acc: 0.8816\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 20s 164us/sample - loss: 0.3168 - acc: 0.8981\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 22s 176us/sample - loss: 0.2804 - acc: 0.9086\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 22s 179us/sample - loss: 0.2535 - acc: 0.9154\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 22s 179us/sample - loss: 0.2357 - acc: 0.9212\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 23s 185us/sample - loss: 0.2193 - acc: 0.9247\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 24s 192us/sample - loss: 0.2065 - acc: 0.9292\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 23s 186us/sample - loss: 0.1958 - acc: 0.9324\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 24s 190us/sample - loss: 0.1850 - acc: 0.9346\n",
      "20800/20800 [==============================] - 2s 95us/sample - loss: 0.3617 - acc: 0.9010\n",
      "================================================Config: [200] => [loss: 0.3616833207642552, acc: 0.9009615182876587]\n",
      "================================================Current Config: [500]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.2040 - acc: 0.9387\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.0821 - acc: 0.9748\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0542 - acc: 0.9830\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.0367 - acc: 0.9881\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.0271 - acc: 0.9913\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 0.0205 - acc: 0.9939\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.0143 - acc: 0.9951\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 247us/sample - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0098 - acc: 0.9967\n",
      "10000/10000 [==============================] - 1s 89us/sample - loss: 0.0939 - acc: 0.9774\n",
      "================================================Config: [500] => [loss: 0.09389589290861113, acc: 0.977400004863739]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 26)                13026     \n",
      "=================================================================\n",
      "Total params: 405,526\n",
      "Trainable params: 405,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 33s 264us/sample - loss: 0.5796 - acc: 0.8253\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 36s 286us/sample - loss: 0.3242 - acc: 0.8957\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 37s 295us/sample - loss: 0.2668 - acc: 0.9124\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 32s 254us/sample - loss: 0.2301 - acc: 0.9222\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 33s 264us/sample - loss: 0.2042 - acc: 0.9305\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 34s 270us/sample - loss: 0.1845 - acc: 0.9344\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 33s 261us/sample - loss: 0.1675 - acc: 0.9406\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 33s 263us/sample - loss: 0.1545 - acc: 0.9438\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 32s 252us/sample - loss: 0.1423 - acc: 0.9481 - loss:\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 32s 259us/sample - loss: 0.1349 - acc: 0.9500\n",
      "20800/20800 [==============================] - 2s 92us/sample - loss: 0.3713 - acc: 0.90600s - loss: 0.4044 \n",
      "================================================Config: [500] => [loss: 0.3712600322074006, acc: 0.9059615135192871]\n",
      "================================================Current Config: [800]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 636,010\n",
      "Trainable params: 636,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 20s 339us/sample - loss: 0.1897 - acc: 0.9434\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 20s 333us/sample - loss: 0.0752 - acc: 0.9767\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 319us/sample - loss: 0.0486 - acc: 0.9846\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 19s 313us/sample - loss: 0.0343 - acc: 0.9891\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 19s 313us/sample - loss: 0.0269 - acc: 0.9911\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 19s 316us/sample - loss: 0.0192 - acc: 0.9937 - loss: 0\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 19s 312us/sample - loss: 0.0175 - acc: 0.9941\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 19s 309us/sample - loss: 0.0156 - acc: 0.9948\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 19s 314us/sample - loss: 0.0123 - acc: 0.9964\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 19s 314us/sample - loss: 0.0125 - acc: 0.9958\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0720 - acc: 0.9818\n",
      "================================================Config: [800] => [loss: 0.07203642539335633, acc: 0.9818000197410583]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 26)                20826     \n",
      "=================================================================\n",
      "Total params: 648,826\n",
      "Trainable params: 648,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 43s 348us/sample - loss: 0.5499 - acc: 0.8314\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 40s 323us/sample - loss: 0.3074 - acc: 0.9002\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 41s 325us/sample - loss: 0.2512 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 40s 322us/sample - loss: 0.2158 - acc: 0.9261\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 35s 281us/sample - loss: 0.1899 - acc: 0.9335\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 35s 277us/sample - loss: 0.1683 - acc: 0.9402\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 33s 264us/sample - loss: 0.1558 - acc: 0.9436\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 34s 270us/sample - loss: 0.1412 - acc: 0.9475\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 35s 281us/sample - loss: 0.1314 - acc: 0.9511\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 35s 277us/sample - loss: 0.1232 - acc: 0.9538\n",
      "20800/20800 [==============================] - 2s 78us/sample - loss: 0.3716 - acc: 0.9109\n",
      "================================================Config: [800] => [loss: 0.37160460432001857, acc: 0.9109134674072266]\n",
      "================================================Current Config: [50 50]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2943 - acc: 0.9155\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1401 - acc: 0.9585\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1065 - acc: 0.9679\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0879 - acc: 0.9733\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0724 - acc: 0.9771\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0627 - acc: 0.9807\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0557 - acc: 0.9821\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0481 - acc: 0.9846\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0441 - acc: 0.9854\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0385 - acc: 0.9876\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1049 - acc: 0.9702\n",
      "================================================Config: [50 50] => [loss: 0.10487841545589036, acc: 0.9702000021934509]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 43,126\n",
      "Trainable params: 43,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 11s 92us/sample - loss: 0.8619 - acc: 0.7440\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 11s 89us/sample - loss: 0.5290 - acc: 0.8377\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 11s 85us/sample - loss: 0.4540 - acc: 0.8591\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 11s 84us/sample - loss: 0.4150 - acc: 0.8705\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 11s 85us/sample - loss: 0.3878 - acc: 0.8785\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 11s 87us/sample - loss: 0.3682 - acc: 0.8823\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 11s 86us/sample - loss: 0.3526 - acc: 0.8865\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 10s 84us/sample - loss: 0.3398 - acc: 0.8905\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 11s 84us/sample - loss: 0.3293 - acc: 0.8932\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 11s 86us/sample - loss: 0.3212 - acc: 0.8950\n",
      "20800/20800 [==============================] - 1s 54us/sample - loss: 0.3853 - acc: 0.8839\n",
      "================================================Config: [50 50] => [loss: 0.38531709297237776, acc: 0.8839423060417175]\n",
      "================================================Current Config: [100  50]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 84,060\n",
      "Trainable params: 84,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2599 - acc: 0.9243\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1117 - acc: 0.9667\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0780 - acc: 0.9758\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0612 - acc: 0.9807\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0477 - acc: 0.9849\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0392 - acc: 0.9873\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0337 - acc: 0.9892\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0282 - acc: 0.9905\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0243 - acc: 0.9918\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0225 - acc: 0.9923\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.0987 - acc: 0.9774\n",
      "================================================Config: [100  50] => [loss: 0.09870955127951128, acc: 0.977400004863739]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 84,876\n",
      "Trainable params: 84,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 13s 108us/sample - loss: 0.7443 - acc: 0.7779\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 13s 106us/sample - loss: 0.4313 - acc: 0.8648\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 13s 107us/sample - loss: 0.3634 - acc: 0.8842\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 13s 105us/sample - loss: 0.3254 - acc: 0.8953\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 13s 107us/sample - loss: 0.3012 - acc: 0.9017\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 13s 108us/sample - loss: 0.2825 - acc: 0.9068\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 13s 108us/sample - loss: 0.2671 - acc: 0.9108\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - ETA: 0s - loss: 0.2557 - acc: 0.913 - 14s 109us/sample - loss: 0.2555 - acc: 0.9139\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 13s 107us/sample - loss: 0.2467 - acc: 0.9167\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 12s 99us/sample - loss: 0.2359 - acc: 0.9201\n",
      "20800/20800 [==============================] - 1s 57us/sample - loss: 0.3554 - acc: 0.8892\n",
      "================================================Config: [100  50] => [loss: 0.35537242458022844, acc: 0.8891826868057251]\n",
      "================================================Current Config: [200 100]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 178,110\n",
      "Trainable params: 178,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.2182 - acc: 0.9349\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.0894 - acc: 0.9722\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.0633 - acc: 0.9801\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: 0.0479 - acc: 0.9843\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.0359 - acc: 0.9880\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 142us/sample - loss: 0.0282 - acc: 0.9905\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0245 - acc: 0.9918\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0217 - acc: 0.9929\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0179 - acc: 0.9938\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.0168 - acc: 0.9947\n",
      "10000/10000 [==============================] - 1s 94us/sample - loss: 0.0783 - acc: 0.9811\n",
      "================================================Config: [200 100] => [loss: 0.07830428805415941, acc: 0.9811000227928162]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 26)                2626      \n",
      "=================================================================\n",
      "Total params: 179,726\n",
      "Trainable params: 179,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 20s 160us/sample - loss: 0.6187 - acc: 0.8108\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 19s 149us/sample - loss: 0.3501 - acc: 0.8878\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 18s 148us/sample - loss: 0.2912 - acc: 0.9047\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 19s 148us/sample - loss: 0.2556 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 18s 148us/sample - loss: 0.2302 - acc: 0.9204\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 19s 149us/sample - loss: 0.2097 - acc: 0.9269\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 18s 145us/sample - loss: 0.1959 - acc: 0.9308\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 19s 151us/sample - loss: 0.1843 - acc: 0.9341\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 19s 154us/sample - loss: 0.1736 - acc: 0.9377\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 19s 151us/sample - loss: 0.1615 - acc: 0.9406\n",
      "20800/20800 [==============================] - 1s 70us/sample - loss: 0.3405 - acc: 0.9046\n",
      "================================================Config: [200 100] => [loss: 0.3404867831770277, acc: 0.904567301273346]\n",
      "================================================Current Config: [200 200]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 199,210\n",
      "Trainable params: 199,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.2093 - acc: 0.9369\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0890 - acc: 0.9720\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0609 - acc: 0.9812\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0463 - acc: 0.9851\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.0355 - acc: 0.9885\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0315 - acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0250 - acc: 0.9918\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0217 - acc: 0.9926\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0210 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0178 - acc: 0.9942\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.1123 - acc: 0.9768\n",
      "================================================Config: [200 200] => [loss: 0.11234730408409924, acc: 0.9768000245094299]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 26)                5226      \n",
      "=================================================================\n",
      "Total params: 202,426\n",
      "Trainable params: 202,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 22s 180us/sample - loss: 0.5942 - acc: 0.8179\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 21s 170us/sample - loss: 0.3309 - acc: 0.8927\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 20s 158us/sample - loss: 0.2727 - acc: 0.9082\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 21s 165us/sample - loss: 0.2381 - acc: 0.9183\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 20s 161us/sample - loss: 0.2124 - acc: 0.9261\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 19s 149us/sample - loss: 0.1947 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 19s 150us/sample - loss: 0.1793 - acc: 0.9356\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 19s 149us/sample - loss: 0.1668 - acc: 0.9396\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 19s 150us/sample - loss: 0.1553 - acc: 0.9425\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 19s 150us/sample - loss: 0.1469 - acc: 0.9461\n",
      "20800/20800 [==============================] - 1s 71us/sample - loss: 0.3401 - acc: 0.9093\n",
      "================================================Config: [200 200] => [loss: 0.3400819396368192, acc: 0.9092788696289062]\n",
      "================================================Current Config: [500 100]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 443,610\n",
      "Trainable params: 443,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.1935 - acc: 0.9423\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 227us/sample - loss: 0.0801 - acc: 0.9756\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 0.0541 - acc: 0.9825\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0412 - acc: 0.9869\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0333 - acc: 0.9892\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 238us/sample - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0251 - acc: 0.9919\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 240us/sample - loss: 0.0190 - acc: 0.9938\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 272us/sample - loss: 0.0193 - acc: 0.9939\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0154 - acc: 0.9951\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 0.0876 - acc: 0.9799\n",
      "================================================Config: [500 100] => [loss: 0.08764193167791819, acc: 0.9799000024795532]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 26)                2626      \n",
      "=================================================================\n",
      "Total params: 445,226\n",
      "Trainable params: 445,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 34s 275us/sample - loss: 0.5595 - acc: 0.8273\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 36s 287us/sample - loss: 0.3166 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 31s 249us/sample - loss: 0.2579 - acc: 0.9134\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 33s 261us/sample - loss: 0.2238 - acc: 0.9232\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 38s 304us/sample - loss: 0.1969 - acc: 0.9306\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 36s 290us/sample - loss: 0.1778 - acc: 0.9362\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - ETA: 0s - loss: 0.1623 - acc: 0.941 - 33s 264us/sample - loss: 0.1624 - acc: 0.9409\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 34s 272us/sample - loss: 0.1511 - acc: 0.9449\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 36s 289us/sample - loss: 0.1422 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 35s 277us/sample - loss: 0.1337 - acc: 0.9496\n",
      "20800/20800 [==============================] - 2s 92us/sample - loss: 0.3630 - acc: 0.9060\n",
      "================================================Config: [500 100] => [loss: 0.36296404542727734, acc: 0.9059615135192871]\n",
      "================================================Current Config: [500 200]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 494,710\n",
      "Trainable params: 494,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 271us/sample - loss: 0.1862 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 0.0786 - acc: 0.9755\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 0.0540 - acc: 0.9822\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 256us/sample - loss: 0.0407 - acc: 0.9864\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 273us/sample - loss: 0.0333 - acc: 0.9891\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 0.0216 - acc: 0.9931\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.0216 - acc: 0.9934\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 246us/sample - loss: 0.0181 - acc: 0.9941\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0183 - acc: 0.9942\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.1065 - acc: 0.9784\n",
      "================================================Config: [500 200] => [loss: 0.10650635645192852, acc: 0.9783999919891357]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 26)                5226      \n",
      "=================================================================\n",
      "Total params: 497,926\n",
      "Trainable params: 497,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 32s 255us/sample - loss: 0.5357 - acc: 0.8330\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 32s 253us/sample - loss: 0.3010 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 31s 252us/sample - loss: 0.2453 - acc: 0.9165\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 32s 253us/sample - loss: 0.2117 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 31s 252us/sample - loss: 0.1879 - acc: 0.9331\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 31s 252us/sample - loss: 0.1697 - acc: 0.9387\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 31s 251us/sample - loss: 0.1542 - acc: 0.9435\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 31s 252us/sample - loss: 0.1448 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 31s 252us/sample - loss: 0.1345 - acc: 0.9499\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 31s 251us/sample - loss: 0.1278 - acc: 0.9517\n",
      "20800/20800 [==============================] - 2s 90us/sample - loss: 0.3639 - acc: 0.9112\n",
      "================================================Config: [500 200] => [loss: 0.36391703873393105, acc: 0.9111538529396057]\n",
      "================================================Current Config: [800 500]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,033,510\n",
      "Trainable params: 1,033,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 433us/sample - loss: 0.1813 - acc: 0.9447\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0790 - acc: 0.9753\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.0542 - acc: 0.9827\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 26s 429us/sample - loss: 0.0410 - acc: 0.9876\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 26s 427us/sample - loss: 0.0352 - acc: 0.9891\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0290 - acc: 0.9909\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 26s 429us/sample - loss: 0.0269 - acc: 0.9918\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.0227 - acc: 0.9933\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 429us/sample - loss: 0.0192 - acc: 0.9942\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0213 - acc: 0.9935\n",
      "10000/10000 [==============================] - 1s 122us/sample - loss: 0.0992 - acc: 0.9792\n",
      "================================================Config: [800 500] => [loss: 0.09922101121918858, acc: 0.979200005531311]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 26)                13026     \n",
      "=================================================================\n",
      "Total params: 1,041,526\n",
      "Trainable params: 1,041,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 53s 428us/sample - loss: 0.4988 - acc: 0.8422\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 52s 417us/sample - loss: 0.2835 - acc: 0.9045\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 52s 416us/sample - loss: 0.2347 - acc: 0.9194\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 52s 416us/sample - loss: 0.2011 - acc: 0.9283\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 57s 460us/sample - loss: 0.1755 - acc: 0.9376\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 57s 456us/sample - loss: 0.1625 - acc: 0.9415\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 57s 459us/sample - loss: 0.1467 - acc: 0.9463\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 57s 456us/sample - loss: 0.1418 - acc: 0.9487\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 57s 456us/sample - loss: 0.1325 - acc: 0.9512\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 59s 475us/sample - loss: 0.1268 - acc: 0.9531\n",
      "20800/20800 [==============================] - 3s 134us/sample - loss: 0.4120 - acc: 0.9106\n",
      "================================================Config: [800 500] => [loss: 0.4120362006843124, acc: 0.9105769395828247]\n",
      "================================================Current Config: [100 100  50]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 94,160\n",
      "Trainable params: 94,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.2492 - acc: 0.9266\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1078 - acc: 0.9671\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0762 - acc: 0.9760\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0592 - acc: 0.9814\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0493 - acc: 0.9836\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0418 - acc: 0.9863\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 125us/sample - loss: 0.0342 - acc: 0.9886\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0299 - acc: 0.9902\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0277 - acc: 0.9907\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0253 - acc: 0.9919\n",
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0961 - acc: 0.9760\n",
      "================================================Config: [100 100  50] => [loss: 0.09606984415383704, acc: 0.9760000109672546]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 94,976\n",
      "Trainable params: 94,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 17s 132us/sample - loss: 0.7150 - acc: 0.7843\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.4108 - acc: 0.8697\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.3464 - acc: 0.8870\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.3105 - acc: 0.8980\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.2845 - acc: 0.9051\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.2679 - acc: 0.9106\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 16s 128us/sample - loss: 0.2503 - acc: 0.9147\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 16s 128us/sample - loss: 0.2400 - acc: 0.9179\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 16s 129us/sample - loss: 0.2289 - acc: 0.9215\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 16s 128us/sample - loss: 0.2195 - acc: 0.9237\n",
      "20800/20800 [==============================] - 2s 87us/sample - loss: 0.3413 - acc: 0.8988\n",
      "================================================Config: [100 100  50] => [loss: 0.3412893247597206, acc: 0.8987980484962463]\n",
      "================================================Current Config: [200 100  50]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 182,660\n",
      "Trainable params: 182,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.2241 - acc: 0.9324\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0940 - acc: 0.9718\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0694 - acc: 0.9780\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0501 - acc: 0.9840\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.0432 - acc: 0.9863\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.0346 - acc: 0.9886\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0219 - acc: 0.9930\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0916 - acc: 0.9773\n",
      "================================================Config: [200 100  50] => [loss: 0.0916300272065062, acc: 0.9772999882698059]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 183,476\n",
      "Trainable params: 183,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 21s 172us/sample - loss: 0.6422 - acc: 0.8034\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.3605 - acc: 0.8829\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.2981 - acc: 0.9013\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.2648 - acc: 0.9114\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.2390 - acc: 0.9188\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.2209 - acc: 0.9235 - loss: 0.2208 - acc: 0.92\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.2042 - acc: 0.9292\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 21s 166us/sample - loss: 0.1921 - acc: 0.9319\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.1817 - acc: 0.9349\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 21s 167us/sample - loss: 0.1728 - acc: 0.9375\n",
      "20800/20800 [==============================] - 2s 96us/sample - loss: 0.3203 - acc: 0.9030\n",
      "================================================Config: [200 100  50] => [loss: 0.3203061849739998, acc: 0.9029807448387146]\n",
      "================================================Current Config: [500 200 100]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 513,810\n",
      "Trainable params: 513,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 0.1960 - acc: 0.9405\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0872 - acc: 0.9737\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 270us/sample - loss: 0.0632 - acc: 0.9800\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0461 - acc: 0.9854\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0397 - acc: 0.9880\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 270us/sample - loss: 0.0325 - acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 269us/sample - loss: 0.0278 - acc: 0.9919\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0238 - acc: 0.9928\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0210 - acc: 0.9933\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 268us/sample - loss: 0.0200 - acc: 0.9941\n",
      "10000/10000 [==============================] - 1s 125us/sample - loss: 0.0760 - acc: 0.9820\n",
      "================================================Config: [500 200 100] => [loss: 0.07601472302361217, acc: 0.9819999933242798]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 26)                2626      \n",
      "=================================================================\n",
      "Total params: 515,426\n",
      "Trainable params: 515,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 35s 277us/sample - loss: 0.5509 - acc: 0.8277\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 34s 273us/sample - loss: 0.3122 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 34s 273us/sample - loss: 0.2581 - acc: 0.9129\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 34s 275us/sample - loss: 0.2246 - acc: 0.9227\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 33s 266us/sample - loss: 0.2027 - acc: 0.9291\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 33s 263us/sample - loss: 0.1841 - acc: 0.9345\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 33s 263us/sample - loss: 0.1708 - acc: 0.9387\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 33s 263us/sample - loss: 0.1567 - acc: 0.9434\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 33s 265us/sample - loss: 0.1482 - acc: 0.9454\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 33s 263us/sample - loss: 0.1439 - acc: 0.9471\n",
      "20800/20800 [==============================] - 2s 111us/sample - loss: 0.3316 - acc: 0.9133\n",
      "================================================Config: [500 200 100] => [loss: 0.3316209264097471, acc: 0.9132692217826843]\n",
      "================================================Current Config: [800 500 200]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 1,130,710\n",
      "Trainable params: 1,130,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 29s 487us/sample - loss: 0.1945 - acc: 0.9409\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 30s 506us/sample - loss: 0.0898 - acc: 0.9732\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 505us/sample - loss: 0.0665 - acc: 0.9800\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 31s 513us/sample - loss: 0.0475 - acc: 0.9857\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 30s 504us/sample - loss: 0.0408 - acc: 0.9871\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 30s 504us/sample - loss: 0.0381 - acc: 0.9888\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 31s 509us/sample - loss: 0.0298 - acc: 0.9911\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 31s 512us/sample - loss: 0.0258 - acc: 0.9922\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 31s 512us/sample - loss: 0.0226 - acc: 0.9935 - loss: 0.0223 - acc\n",
      "10000/10000 [==============================] - 2s 164us/sample - loss: 0.0989 - acc: 0.9797\n",
      "================================================Config: [800 500 200] => [loss: 0.09888817813481036, acc: 0.9797000288963318]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 500)               400500    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 26)                5226      \n",
      "=================================================================\n",
      "Total params: 1,133,926\n",
      "Trainable params: 1,133,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 65s 524us/sample - loss: 0.5179 - acc: 0.8364\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 65s 520us/sample - loss: 0.3010 - acc: 0.9003\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 65s 524us/sample - loss: 0.2476 - acc: 0.9159\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 66s 525us/sample - loss: 0.2151 - acc: 0.9259\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 65s 523us/sample - loss: 0.1918 - acc: 0.9325\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 65s 521us/sample - loss: 0.1761 - acc: 0.9372\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 65s 523us/sample - loss: 0.1649 - acc: 0.9418\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 65s 521us/sample - loss: 0.1533 - acc: 0.9449\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 65s 520us/sample - loss: 0.1488 - acc: 0.9461\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 65s 522us/sample - loss: 0.1428 - acc: 0.9486\n",
      "20800/20800 [==============================] - 3s 148us/sample - loss: 0.3416 - acc: 0.9150\n",
      "================================================Config: [800 500 200] => [loss: 0.3415987311794624, acc: 0.9149519205093384]\n",
      "================================================Current Config: [800 200  50]\n",
      "====================Digits====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 200)               160200    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 798,760\n",
      "Trainable params: 798,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 23s 387us/sample - loss: 0.1922 - acc: 0.9416\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 375us/sample - loss: 0.0856 - acc: 0.9735\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.0593 - acc: 0.9814\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 376us/sample - loss: 0.0459 - acc: 0.9859\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 23s 378us/sample - loss: 0.0376 - acc: 0.9882\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 376us/sample - loss: 0.0298 - acc: 0.9905\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.0278 - acc: 0.9912\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 23s 378us/sample - loss: 0.0219 - acc: 0.9928\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.0202 - acc: 0.9936\n",
      "10000/10000 [==============================] - 1s 147us/sample - loss: 0.0826 - acc: 0.9800\n",
      "================================================Config: [800 200  50] => [loss: 0.08262525909396863, acc: 0.9800000190734863]\n",
      "====================Aplhabets====================:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 200)               160200    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 26)                1326      \n",
      "=================================================================\n",
      "Total params: 799,576\n",
      "Trainable params: 799,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "124800/124800 [==============================] - 48s 383us/sample - loss: 0.5567 - acc: 0.8271\n",
      "Epoch 2/10\n",
      "124800/124800 [==============================] - 45s 364us/sample - loss: 0.3079 - acc: 0.8995\n",
      "Epoch 3/10\n",
      "124800/124800 [==============================] - 45s 362us/sample - loss: 0.2526 - acc: 0.9148\n",
      "Epoch 4/10\n",
      "124800/124800 [==============================] - 45s 364us/sample - loss: 0.2182 - acc: 0.9243\n",
      "Epoch 5/10\n",
      "124800/124800 [==============================] - 45s 364us/sample - loss: 0.1931 - acc: 0.9322\n",
      "Epoch 6/10\n",
      "124800/124800 [==============================] - 45s 363us/sample - loss: 0.1765 - acc: 0.9373 - loss: 0.1764 - acc: 0.93\n",
      "Epoch 7/10\n",
      "124800/124800 [==============================] - 45s 364us/sample - loss: 0.1618 - acc: 0.9408\n",
      "Epoch 8/10\n",
      "124800/124800 [==============================] - 46s 366us/sample - loss: 0.1505 - acc: 0.9452\n",
      "Epoch 9/10\n",
      "124800/124800 [==============================] - 48s 382us/sample - loss: 0.1412 - acc: 0.9483\n",
      "Epoch 10/10\n",
      "124800/124800 [==============================] - 48s 381us/sample - loss: 0.1338 - acc: 0.9502\n",
      "20800/20800 [==============================] - 3s 135us/sample - loss: 0.3390 - acc: 0.9126\n",
      "================================================Config: [800 200  50] => [loss: 0.33899692346402355, acc: 0.9126442074775696]\n"
     ]
    }
   ],
   "source": [
    "#Getting Configs\n",
    "configs = []\n",
    "with open('configs.csv') as f:\n",
    "    configs = [x.strip() for x in f.readlines()]\n",
    " \n",
    "for i in range(len(configs)):\n",
    "    config = np.array(configs[i].split(','), dtype=np.uint)\n",
    "    print(\"================================================Current Config:\", config)\n",
    "    \n",
    "    n_epochs = 10\n",
    "    #For Digits\n",
    "    print(\"====================Digits====================:\")\n",
    "    dims = d_X_train.shape[1]\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(config[0], activation=keras.activations.relu, input_shape=(dims,)))\n",
    "    for hu in config[1:]:\n",
    "        model.add(keras.layers.Dense(hu, activation=keras.activations.relu))\n",
    "    model.add(keras.layers.Dense(d_classes, activation=keras.activations.softmax))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                     loss=tf.keras.losses.sparse_categorical_crossentropy ,\n",
    "                     metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(d_X_train, d_y_train, epochs = n_epochs)\n",
    "    loss, acc = model.evaluate(d_X_test, d_y_test)\n",
    "    print(\"================================================Config: {} => [loss: {}, acc: {}]\".format(config, loss, acc))\n",
    "    \n",
    "    #For Alphabets\n",
    "    print(\"====================Aplhabets====================:\")\n",
    "    dims = a_X_train.shape[1]\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(config[0], activation=keras.activations.relu, input_shape=(dims,)))\n",
    "    for hu in config[1:]:\n",
    "        model.add(keras.layers.Dense(hu, activation=keras.activations.relu))\n",
    "    model.add(keras.layers.Dense(a_classes, activation=keras.activations.softmax))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                     loss=tf.keras.losses.sparse_categorical_crossentropy ,\n",
    "                     metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(a_X_train, a_y_train, epochs = n_epochs)\n",
    "    loss, acc = model.evaluate(a_X_test, a_y_test)\n",
    "    print(\"================================================Config: {} => [loss: {}, acc: {}]\".format(config, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '[50]' '0.0439' '0.9861' '0.0926' '0.9743' '0.3772' '0.8813'\n",
      "  '0.4386' '0.8691']\n",
      " ['2' '[100]' '0.0206' '0.9935' '0.0883' '0.9747' '0.2668' '0.9133'\n",
      "  '0.3742' '0.889']\n",
      " ['3' '[200]' '0.0122' '0.9959' '0.0786' '0.9797' '0.185' '0.9346'\n",
      "  '0.3616' '0.9009']\n",
      " ['4' '[500]' '0.0098' '0.9967' '0.0938' '0.9774' '0.1349' '0.95'\n",
      "  '0.3712' '0.9059']\n",
      " ['5' '[800]' '0.0125' '0.9958' '0.072' '0.9818' '0.1232' '0.9538'\n",
      "  '0.3716' '0.9109']\n",
      " ['6' '[50-50]' '0.0385' '0.9876' '0.1048' '0.9702' '0.3212' '0.895'\n",
      "  '0.3853' '0.8839']\n",
      " ['7' '[100-50]' '0.0225' '0.9923' '0.0987' '0.9774' '0.2359' '0.9201'\n",
      "  '0.3553' '0.8891']\n",
      " ['8' '[200-100]' '0.0168' '0.9947' '0.0783' '0.9811' '0.1615' '0.9406'\n",
      "  '0.3404' '0.9045']\n",
      " ['9' '[200-200]' '0.0178' '0.9942' '0.1123' '0.9768' '0.1469' '0.9461'\n",
      "  '0.34' '0.9092']\n",
      " ['10' '[500-100]' '0.0154' '0.9951' '0.0876' '0.9799' '0.363' '0.906'\n",
      "  '0.3629' '0.9059']\n",
      " ['11' '[500-200]' '0.0183' '0.9942' '0.1065' '0.9783' '0.3639' '0.9112'\n",
      "  '0.3639' '0.9111']\n",
      " ['12' '[800-500]' '0.0213' '0.9935' '0.0992' '0.9792' '0.1268' '0.9531'\n",
      "  '0.412' '0.9105']\n",
      " ['13' '[100-100-50]' '0.0253' '0.9919' '0.096' '0.976' '0.3413' '0.9237'\n",
      "  '0.3412' '0.8987']\n",
      " ['14' '[200-100-50]' '0.0219' '0.993' '0.0916' '0.9772' '0.1728'\n",
      "  '0.9375' '0.3203' '0.9029']\n",
      " ['15' '[500-200-100]' '0.02' '0.9941' '0.076' '0.982' '0.1439' '0.9471'\n",
      "  '0.3316' '0.9133']\n",
      " ['16' '[800-500-200]' '0.0226' '0.9935' '0.0989' '0.9797' '0.1428'\n",
      "  '0.9486' '0.3415' '0.9149']\n",
      " ['17' '[800-200-50]' '0.0202' '0.9936' '0.0826' '0.98' '0.1338' '0.9502'\n",
      "  '0.3389' '0.9126']]\n"
     ]
    }
   ],
   "source": [
    "eval_ar = np.loadtxt('model_evaluation.csv', delimiter=',', dtype=str)\n",
    "print(eval_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 10)\n",
      "Digits:\n",
      " Selected Config: [500-200-100]\n",
      " Acc: 0.982\n",
      "Alphabets:\n",
      " Selected Config: [800-500-200]\n",
      " Acc: 0.9149\n"
     ]
    }
   ],
   "source": [
    "print(eval_ar.shape)\n",
    "az_i = np.argmax(eval_ar[:, 9])\n",
    "dg_i = np.argmax(eval_ar[:, 5])\n",
    "print(\"Digits:\\n Selected Config: {}\\n Acc: {}\".format(eval_ar[dg_i, 1], eval_ar[dg_i, 5]))\n",
    "print(\"Alphabets:\\n Selected Config: {}\\n Acc: {}\".format(eval_ar[az_i, 1], eval_ar[az_i, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_cpu_env]",
   "language": "python",
   "name": "conda-env-tf_cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
